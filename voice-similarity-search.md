# Há»‡ thá»‘ng TÃ¬m kiáº¿m Giá»ng nÃ³i Phá»¥ ná»¯ dá»±a trÃªn Äá»™ tÆ°Æ¡ng Ä‘á»“ng

## ğŸ“‹ Tá»•ng quan

XÃ¢y dá»±ng há»‡ thá»‘ng tÃ¬m kiáº¿m Ã¢m thanh giá»ng nÃ³i phá»¥ ná»¯ sá»­ dá»¥ng **similarity search** vá»›i vector embeddings. Há»‡ thá»‘ng nháº­n Ä‘áº§u vÃ o lÃ  file Ã¢m thanh giá»ng phá»¥ ná»¯, tráº£ vá» 5 file Ã¢m thanh tÆ°Æ¡ng Ä‘á»“ng nháº¥t theo thá»© tá»± giáº£m dáº§n.

**Má»¥c tiÃªu há»c thuáº­t:**

- Thu tháº­p/xÃ¢y dá»±ng dataset â‰¥500 files Ã¢m thanh giá»ng phá»¥ ná»¯
- TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng Ã¢m thanh (pitch, MFCC, spectral features)
- XÃ¢y dá»±ng CSDL vector cho similarity search
- Demo há»‡ thá»‘ng vá»›i giao diá»‡n Streamlit
- ÄÃ¡nh giÃ¡ káº¿t quáº£ tÃ¬m kiáº¿m

---

## ğŸ¯ TiÃªu chÃ­ thÃ nh cÃ´ng

| TiÃªu chÃ­               | Má»¥c tiÃªu                                                  |
| ---------------------- | --------------------------------------------------------- |
| **Dataset**            | â‰¥500 files Ã¢m thanh giá»ng phá»¥ ná»¯, cÃ¹ng Ä‘á»™ dÃ i             |
| **Feature Extraction** | CÃ³ â‰¥5 Ä‘áº·c trÆ°ng Ã¢m thanh (pitch, MFCC, spectral, etc.)    |
| **Vector DB**          | LÆ°u trá»¯ embeddings vá»›i FAISS/Pinecone                     |
| **Search Accuracy**    | Top-5 results cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng há»£p lÃ½ (manual evaluation) |
| **Demo UI**            | Streamlit app hoáº¡t Ä‘á»™ng, upload file â†’ hiá»ƒn thá»‹ top-5     |
| **Documentation**      | SÆ¡ Ä‘á»“ há»‡ thá»‘ng, giáº£i thÃ­ch feature extraction             |

---

## ğŸ› ï¸ Tech Stack

| Component                | Technology                               | LÃ½ do lá»±a chá»n                                |
| ------------------------ | ---------------------------------------- | --------------------------------------------- |
| **Backend**              | Python 3.10+                             | Há»‡ sinh thÃ¡i máº¡nh cho audio processing        |
| **Frontend**             | Streamlit                                | Nhanh chÃ³ng táº¡o UI demo, phÃ¹ há»£p MVP          |
| **Audio Processing**     | librosa, pydub, soundfile                | Standard libraries cho feature extraction     |
| **Vector DB (Primary)**  | FAISS                                    | Local, miá»…n phÃ­, nhanh, phÃ¹ há»£p research      |
| **Vector DB (Optional)** | Pinecone                                 | Cloud-based, scalable (cÃ³ thá»ƒ dÃ¹ng free tier) |
| **Feature Extraction**   | librosa (MFCC, pitch, spectral)          | Industry standard                             |
| **Environment**          | Conda (`voice-search`)                   | Quáº£n lÃ½ dependencies dá»… dÃ ng                  |
| **Data Download**        | yt-dlp, requests, datasets (HuggingFace) | Thu tháº­p audio tá»« nhiá»u nguá»“n                 |

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n

```
Female-voice-similarity-search/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Audio files táº£i vá» (500+ files)
â”‚   â”œâ”€â”€ processed/              # Audio sau khi normalize/trim
â”‚   â””â”€â”€ metadata.csv            # ThÃ´ng tin files: path, duration, source
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ vectors/                # FAISS index files
â”‚   â”œâ”€â”€ features.npy            # Feature vectors (n_samples Ã— n_features)
â”‚   â””â”€â”€ index_mapping.json      # Mapping: vector_id â†’ audio_path
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_collection/
â”‚   â”‚   â”œâ”€â”€ download_audio.py       # CÃ´ng cá»¥ táº£i audio tá»« nhiá»u nguá»“n
â”‚   â”‚   â””â”€â”€ preprocess_audio.py     # Normalize, trim, resample
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_extraction/
â”‚   â”‚   â”œâ”€â”€ extractor.py            # Feature extraction pipeline
â”‚   â”‚   â””â”€â”€ features_config.py      # Config: MFCC params, pitch range
â”‚   â”‚
â”‚   â”œâ”€â”€ vector_database/
â”‚   â”‚   â”œâ”€â”€ faiss_manager.py        # FAISS index CRUD
â”‚   â”‚   â””â”€â”€ pinecone_manager.py     # Pinecone integration (optional)
â”‚   â”‚
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â””â”€â”€ similarity_search.py    # Search pipeline: audio â†’ features â†’ top-k
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ audio_utils.py          # Helper functions
â”‚       â””â”€â”€ visualization.py        # Waveform, spectrogram plots
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Main Streamlit UI
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb       # EDA: dataset statistics
â”‚   â”œâ”€â”€ 02_feature_analysis.ipynb       # Feature importance analysis
â”‚   â””â”€â”€ 03_search_evaluation.ipynb     # ÄÃ¡nh giÃ¡ káº¿t quáº£ tÃ¬m kiáº¿m
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_feature_extraction.py
â”‚   â””â”€â”€ test_search_pipeline.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ system_architecture.md      # SÆ¡ Ä‘á»“ há»‡ thá»‘ng
â”‚   â”œâ”€â”€ feature_extraction.md       # Giáº£i thÃ­ch cÃ¡c features
â”‚   â””â”€â”€ evaluation_report.md        # BÃ¡o cÃ¡o Ä‘Ã¡nh giÃ¡
â”‚
â”œâ”€â”€ environment.yml             # Conda environment spec
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md
```

---

## Kiáº¿n trÃºc há»‡ thá»‘ng

```mermaid
flowchart TD
    A[Audio Input<br/>New female voice] --> B[Preprocessing<br/>Trim, Normalize, Resample]
    B --> C[Feature Extraction<br/>MFCC, Pitch, Spectral, ZCR, Energy]
    C --> D[Vector Embedding<br/>Concatenate features]
    D --> E{Vector Database}

    E -->|FAISS| F1[Local Index<br/>L2 Distance]
    E -->|Pinecone| F2[Cloud Index<br/>Cosine Similarity]

    F1 --> G[Top-5 Similar Vectors]
    F2 --> G

    G --> H[Map to Audio Files]
    H --> I[Results Display<br/>Audio playback + similarity scores]

    J[Dataset<br/>500+ female voices] --> K[Batch Processing]
    K --> L[Build Vector Index]
    L --> E

    style A fill:#e1f5ff
    style I fill:#c8e6c9
    style E fill:#fff9c4
```

### Quy trÃ¬nh hoáº¡t Ä‘á»™ng

1. **Offline: XÃ¢y dá»±ng database**
    - Táº£i 500+ audio files â†’ `data/raw/`
    - Preprocessing: trim silence, normalize volume, resample to 16kHz
    - Extract features cho má»—i file â†’ feature vectors (chiá»u ~128-256)
    - Build FAISS index vÃ  lÆ°u mapping

2. **Online: Similarity search**
    - User upload audio file má»›i
    - Preprocess â†’ Extract features
    - Query FAISS index â†’ Top-5 nearest neighbors
    - Tráº£ vá» file paths + similarity scores
    - Streamlit hiá»ƒn thá»‹ káº¿t quáº£ (audio player, waveform, scores)

---

## Chi tiáº¿t cÃ¡c Ä‘áº·c trÆ°ng Ã¢m thanh (Features)

| Feature                | MÃ´ táº£                                              | KÃ­ch thÆ°á»›c          | ThÆ° viá»‡n                             |
| ---------------------- | -------------------------------------------------- | ------------------- | ------------------------------------ |
| **MFCC**               | Mel-Frequency Cepstral Coefficients (voice timbre) | 13-40 coeffs        | `librosa.feature.mfcc`               |
| **Pitch (F0)**         | Fundamental frequency (cao Ä‘á»™ giá»ng nÃ³i)           | Mean, Std, Min, Max | `librosa.pyin` hoáº·c `parselmouth`    |
| **Spectral Centroid**  | Trá»ng tÃ¢m phá»• táº§n sá»‘ (brightness)                  | Mean, Std           | `librosa.feature.spectral_centroid`  |
| **Spectral Rolloff**   | Táº§n sá»‘ mÃ  dÆ°á»›i Ä‘Ã³ cÃ³ 85% nÄƒng lÆ°á»£ng                | Mean, Std           | `librosa.feature.spectral_rolloff`   |
| **Zero Crossing Rate** | Tá»‘c Ä‘á»™ Ä‘á»•i dáº¥u tÃ­n hiá»‡u (noisiness)                | Mean, Std           | `librosa.feature.zero_crossing_rate` |
| **RMS Energy**         | NÄƒng lÆ°á»£ng tÃ­n hiá»‡u                                | Mean, Std           | `librosa.feature.rms`                |
| **Chroma**             | PhÃ¢n bá»‘ nÄƒng lÆ°á»£ng theo 12 pitch classes           | 12 values           | `librosa.feature.chroma_stft`        |

**Tá»•ng sá»‘ features:** ~40-80 dimensions (tuá»³ config)

**LÃ½ do lá»±a chá»n:**

- **MFCC**: Standard cho voice recognition, náº¯m báº¯t timbre
- **Pitch**: Äáº·c trÆ°ng then chá»‘t Ä‘á»ƒ phÃ¢n biá»‡t giá»ng nÃ³i
- **Spectral features**: MÃ´ táº£ cháº¥t lÆ°á»£ng Ã¢m thanh
- **Energy/ZCR**: PhÃ¢n biá»‡t voiced/unvoiced segments

---

## ğŸ“ Task Breakdown - Phase by Phase

### **PHASE 1: Environment Setup**

#### Task 1.1: Táº¡o Conda Environment

- **Agent:** DevOps / Setup
- **Input:** `environment.yml` spec
- **Output:** Conda env `voice-search` activated
- **Verify:** `conda env list` hiá»ƒn thá»‹ `voice-search`

```bash
conda create -n voice-search python=3.10 -y
conda activate voice-search
pip install streamlit librosa pydub soundfile numpy pandas faiss-cpu pinecone-client yt-dlp
```

#### Task 1.2: Táº¡o cáº¥u trÃºc thÆ° má»¥c

- **Agent:** DevOps
- **Input:** Folder structure specification
- **Output:** Táº¥t cáº£ folders Ä‘Æ°á»£c táº¡o trong project root
- **Verify:** `tree` command hoáº·c `ls -R` show full structure

---

### **PHASE 2: Data Collection**

#### Task 2.1: Build Audio Download Tool

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`
- **Input:** Danh sÃ¡ch nguá»“n datasets (VoxCeleb, Common Voice, YouTube)
- **Output:** `src/data_collection/download_audio.py`
- **Features:**
    - Download tá»« HuggingFace `datasets` (VoxCeleb subset)
    - Download tá»« YouTube vá»›i `yt-dlp` (female voice channels)
    - Filter chá»‰ giá»ng phá»¥ ná»¯ (metadata hoáº·c manual curation)
- **Verify:** Run script â†’ download Ã­t nháº¥t 50 files thá»­ nghiá»‡m

**Gá»£i Ã½ datasets:**

- [VoxCeleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html): Celebrity voices (cÃ³ female subset)
- [Common Voice](https://commonvoice.mozilla.org/vi): Crowdsourced, cÃ³ filter gender
- [LibriSpeech](http://www.openslr.org/12/): Audiobooks (cÃ³ female speakers)

#### Task 2.2: Collect 500+ Audio Files

- **Agent:** Manual + Script
- **Input:** Download script + dataset URLs
- **Output:** `data/raw/` chá»©a â‰¥500 `.wav` files + `metadata.csv`
- **Verify:**
    - `len(os.listdir('data/raw'))` >= 500
    - `pandas.read_csv('data/metadata.csv').shape[0]` >= 500

#### Task 2.3: Audio Preprocessing

- **Agent:** `backend-specialist`
- **Input:** Raw audio files (cÃ³ thá»ƒ khÃ¡c sample rate, Ä‘á»™ dÃ i)
- **Output:** `data/processed/` vá»›i files Ä‘á»“ng nháº¥t (16kHz, 3-5s duration)
- **Script:** `src/data_collection/preprocess_audio.py`
- **Verify:**
    - All files in `processed/` cÃ³ cÃ¹ng sample rate (16000 Hz)
    - Duration variance < 0.5s

**Preprocessing steps:**

```python
# Pseudo-code
for audio_file in raw_files:
    audio, sr = librosa.load(audio_file, sr=16000)  # Resample
    audio = librosa.effects.trim(audio)[0]           # Trim silence
    audio = librosa.util.normalize(audio)            # Normalize volume

    # Chá»n segment cá»‘ Ä‘á»‹nh (e.g., 3 seconds)
    target_length = 3 * 16000  # 3s Ã— 16kHz
    if len(audio) > target_length:
        audio = audio[:target_length]  # Crop
    else:
        audio = np.pad(audio, (0, target_length - len(audio)))  # Pad

    soundfile.write(f'processed/{filename}', audio, 16000)
```

---

### **PHASE 3: Feature Extraction**

#### Task 3.1: Design Feature Extraction Pipeline

- **Agent:** `backend-specialist`
- **Skill:** `python-patterns`, audio processing knowledge
- **Input:** Preprocessed audio files
- **Output:** `src/feature_extraction/extractor.py`
- **Functions:**
    - `extract_mfcc(audio, sr)` â†’ shape (13,)
    - `extract_pitch_features(audio, sr)` â†’ shape (4,) # mean, std, min, max
    - `extract_spectral_features(audio, sr)` â†’ shape (6,)
    - `extract_all_features(audio_path)` â†’ shape (40,)
- **Verify:**
    - Test vá»›i 1 file â†’ vector shape = (40,)
    - No NaN values in output

#### Task 3.2: Batch Extract Features for All Audio

- **Agent:** Script execution
- **Input:** `data/processed/` (500+ files)
- **Output:**
    - `database/features.npy` shape (500, 40)
    - `database/index_mapping.json` {0: "file1.wav", 1: "file2.wav", ...}
- **Script:** Sá»­ dá»¥ng `extractor.py` vá»›i multiprocessing
- **Verify:**
    - `features.npy` shape matches sá»‘ lÆ°á»£ng files
    - No missing entries in `index_mapping.json`

```python
# Pseudo-code
features_list = []
mapping = {}

for idx, audio_file in enumerate(processed_files):
    features = extract_all_features(audio_file)
    features_list.append(features)
    mapping[idx] = audio_file

np.save('database/features.npy', np.array(features_list))
json.dump(mapping, open('database/index_mapping.json', 'w'))
```

---

### **PHASE 4: Vector Database Setup**

#### Task 4.1: Build FAISS Index

- **Agent:** `backend-specialist`
- **Skill:** `database-design`
- **Input:** `database/features.npy`
- **Output:** `database/vectors/faiss_index.bin`
- **Script:** `src/vector_database/faiss_manager.py`

```python
import faiss
import numpy as np

# Load features
features = np.load('database/features.npy').astype('float32')
dimension = features.shape[1]  # 40

# Create FAISS index (L2 distance)
index = faiss.IndexFlatL2(dimension)
index.add(features)  # Add all vectors

# Save index
faiss.write_index(index, 'database/vectors/faiss_index.bin')
```

- **Verify:**
    - `index.ntotal` == sá»‘ lÆ°á»£ng audio files
    - Test search vá»›i 1 vector â†’ tráº£ vá» indices há»£p lá»‡

#### Task 4.2: (Optional) Setup Pinecone

- **Agent:** `backend-specialist`
- **Input:** Pinecone API key, features array
- **Output:** Pinecone index vá»›i all vectors uploaded
- **Script:** `src/vector_database/pinecone_manager.py`
- **Verify:** Query Pinecone index â†’ tráº£ vá» káº¿t quáº£

> **Note:** FAISS lÃ  primary, Pinecone optional cho comparison

---

### **PHASE 5: Similarity Search Pipeline**

#### Task 5.1: Build Search Module

- **Agent:** `backend-specialist`
- **Input:** Query audio file + FAISS index
- **Output:** `src/search/similarity_search.py`
- **Functions:**
    - `search_similar(query_audio_path, top_k=5)` â†’ List[(file_path, similarity_score)]

```python
def search_similar(query_audio_path, top_k=5):
    # 1. Extract features from query audio
    query_features = extract_all_features(query_audio_path)
    query_vector = query_features.reshape(1, -1).astype('float32')

    # 2. Load FAISS index
    index = faiss.read_index('database/vectors/faiss_index.bin')

    # 3. Search
    distances, indices = index.search(query_vector, top_k)

    # 4. Map to file paths
    mapping = json.load(open('database/index_mapping.json'))
    results = [
        (mapping[str(idx)], float(dist))
        for idx, dist in zip(indices[0], distances[0])
    ]

    return results
```

- **Verify:**
    - Test vá»›i audio tá»« database â†’ top-1 pháº£i lÃ  chÃ­nh nÃ³ (distance â‰ˆ 0)
    - Test vá»›i audio má»›i â†’ tráº£ vá» 5 káº¿t quáº£ há»£p lÃ½

---

### **PHASE 6: Streamlit UI**

#### Task 6.1: Build Streamlit App

- **Agent:** `frontend-specialist` hoáº·c `backend-specialist`
- **Skill:** `clean-code`
- **Input:** Search pipeline + audio files
- **Output:** `app/streamlit_app.py`

**UI Features:**

1. **Upload Section:**
    - File uploader (accept `.wav`, `.mp3`, `.flac`)
    - Display uploaded audio waveform

2. **Search Results:**
    - Show top-5 similar audio files
    - For each result:
        - Audio player
        - Similarity score (normalized 0-100%)
        - Waveform plot
        - File name

3. **System Info:**
    - Total files in database
    - Feature dimensions
    - Database type (FAISS/Pinecone)

```python
import streamlit as st
from search.similarity_search import search_similar
import librosa
import librosa.display
import matplotlib.pyplot as plt

st.title("ğŸ¤ Há»‡ thá»‘ng TÃ¬m kiáº¿m Giá»ng nÃ³i Phá»¥ ná»¯")

# Upload
uploaded_file = st.file_uploader("Táº£i lÃªn file Ã¢m thanh giá»ng phá»¥ ná»¯", type=['wav', 'mp3'])

if uploaded_file:
    # Save temp file
    with open('temp_query.wav', 'wb') as f:
        f.write(uploaded_file.read())

    # Display query audio
    st.subheader("Ã‚m thanh tÃ¬m kiáº¿m:")
    st.audio('temp_query.wav')

    # Search
    with st.spinner('Äang tÃ¬m kiáº¿m...'):
        results = search_similar('temp_query.wav', top_k=5)

    # Display results
    st.subheader("ğŸ” Top 5 káº¿t quáº£ tÆ°Æ¡ng Ä‘á»“ng:")
    for rank, (file_path, distance) in enumerate(results, 1):
        st.write(f"**#{rank} - Äá»™ tÆ°Æ¡ng Ä‘á»“ng: {100 - distance:.2f}%**")
        st.audio(file_path)

        # Waveform
        audio, sr = librosa.load(file_path)
        fig, ax = plt.subplots()
        librosa.display.waveshow(audio, sr=sr, ax=ax)
        st.pyplot(fig)
        st.write("---")
```

- **Verify:**
    - Run `streamlit run app/streamlit_app.py`
    - Upload audio â†’ See 5 results with playback

---

### **PHASE 7: Documentation**

#### Task 7.1: System Architecture Document

- **Agent:** Documentation
- **Output:** `docs/system_architecture.md`
- **Content:**
    - SÆ¡ Ä‘á»“ khá»‘i há»‡ thá»‘ng (Mermaid diagram)
    - Quy trÃ¬nh xá»­ lÃ½: Input â†’ Features â†’ Search â†’ Output
    - Giáº£i thÃ­ch tá»«ng module

#### Task 7.2: Feature Extraction Explanation

- **Output:** `docs/feature_extraction.md`
- **Content:**
    - Giáº£i thÃ­ch chi tiáº¿t tá»«ng loáº¡i feature
    - LÃ½ do lá»±a chá»n
    - CÃ´ng thá»©c toÃ¡n há»c (MFCC, pitch detection)
    - VÃ­ dá»¥ minh hoáº¡ (plots)

#### Task 7.3: Evaluation Report

- **Output:** `docs/evaluation_report.md`
- **Content:**
    - Thá»‘ng kÃª dataset (sá»‘ lÆ°á»£ng files, Ä‘á»™ dÃ i trung bÃ¬nh, phÃ¢n bá»‘)
    - ÄÃ¡nh giÃ¡ káº¿t quáº£ tÃ¬m kiáº¿m (manual evaluation vá»›i 10-20 queries)
    - PhÃ¢n tÃ­ch Ä‘á»™ chÃ­nh xÃ¡c: Top-5 cÃ³ giá»ng tÆ°Æ¡ng Ä‘á»“ng khÃ´ng?
    - Káº¿t luáº­n vÃ  hÆ°á»›ng cáº£i thiá»‡n

---

## PHASE X: VERIFICATION (Final Checklist)

> ğŸ”´ **Thá»±c thi cÃ¡c bÆ°á»›c nÃ y TRÆ¯á»šC KHI Ä‘Ã¡nh dáº¥u project hoÃ n thÃ nh**

### X.1: Functional Tests

- [ ] **Dataset:** CÃ³ â‰¥500 files trong `data/processed/`, cÃ¹ng Ä‘á»™ dÃ i
- [ ] **Feature Extraction:**
    - Run `test_feature_extraction.py` â†’ All tests pass
    - Verify: features.npy khÃ´ng cÃ³ NaN
- [ ] **FAISS Index:**
    - Load index thÃ nh cÃ´ng
    - Search vá»›i 1 audio trong database â†’ top-1 lÃ  chÃ­nh nÃ³
- [ ] **Search Pipeline:**
    - Test vá»›i 5 query audios khÃ¡c nhau
    - Má»—i query tráº£ vá» 5 káº¿t quáº£ há»£p lÃ½ (manual check)
- [ ] **Streamlit UI:**
    - App khá»Ÿi Ä‘á»™ng khÃ´ng lá»—i: `streamlit run app/streamlit_app.py`
    - Upload audio â†’ hiá»ƒn thá»‹ 5 results vá»›i audio playback
    - Waveform plots render Ä‘Ãºng

### X.2: Code Quality

```bash
# Lint check
# turbo
python -m pylint src/ app/ --disable=C0111,R0903

# Type hints check (if used)
# turbo
python -m mypy src/ app/ --ignore-missing-imports
```

- [ ] No critical linting errors
- [ ] Code follows clean-code principles (src readable, modular)

### X.3: Security Scan

```bash
# turbo
python .agent/skills/vulnerability-scanner/scripts/security_scan.py .
```

- [ ] No hardcoded API keys
- [ ] No critical vulnerabilities in dependencies

### X.4: Documentation Complete

- [ ] `README.md` cÃ³ hÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  cháº¡y
- [ ] `docs/system_architecture.md` cÃ³ sÆ¡ Ä‘á»“ há»‡ thá»‘ng
- [ ] `docs/feature_extraction.md` giáº£i thÃ­ch cÃ¡c features
- [ ] `docs/evaluation_report.md` cÃ³ Ä‘Ã¡nh giÃ¡ káº¿t quáº£

### X.5: Demo Ready

- [ ] Chuáº©n bá»‹ 3-5 audio samples Ä‘á»ƒ demo trá»±c tiáº¿p
- [ ] Cháº¡y search vá»›i cÃ¡c samples â†’ káº¿t quáº£ há»£p lÃ½
- [ ] Screenshots hoáº·c video demo UI

---

## ğŸ“š Dependencies & Installation

**Conda environment:**

```bash
conda create -n voice-search python=3.10 -y
conda activate voice-search
```

**Core packages** (`requirements.txt`):

```
streamlit>=1.28.0
librosa>=0.10.0
soundfile>=0.12.0
pydub>=0.25.0
numpy>=1.24.0
pandas>=2.0.0
faiss-cpu>=1.7.4        # hoáº·c faiss-gpu náº¿u cÃ³ GPU
pinecone-client>=2.2.0  # optional
yt-dlp>=2023.0.0
matplotlib>=3.7.0
scikit-learn>=1.3.0     # for evaluation metrics
datasets>=2.14.0        # HuggingFace datasets
```

**Install:**

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Quick Start Guide

```bash
# 1. Setup environment
conda create -n voice-search python=3.10 -y
conda activate voice-search
pip install -r requirements.txt

# 2. Download dataset
python src/data_collection/download_audio.py --source voxceleb --samples 500

# 3. Preprocess audio
python src/data_collection/preprocess_audio.py

# 4. Extract features
python src/feature_extraction/extractor.py --batch-process

# 5. Build FAISS index
python src/vector_database/faiss_manager.py --build-index

# 6. Run Streamlit app
streamlit run app/streamlit_app.py
```

---

## ğŸ”¬ Evaluation Metrics

Äá»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng tÃ¬m kiáº¿m:

1. **Manual Evaluation:**
    - Chá»n 20 audio queries
    - Vá»›i má»—i query, kiá»ƒm tra top-5 results
    - ÄÃ¡nh giÃ¡: CÃ³ bao nhiÃªu results thá»±c sá»± tÆ°Æ¡ng Ä‘á»“ng (subjective)

2. **Precision@5:**
    - Náº¿u cÃ³ ground truth (cÃ¹ng speaker)
    - P@5 = (sá»‘ káº¿t quáº£ Ä‘Ãºng trong top-5) / 5

3. **Feature Importance Analysis:**
    - Thá»­ nghiá»‡m loáº¡i bá» tá»«ng nhÃ³m features
    - Xem feature nÃ o áº£nh hÆ°á»Ÿng nhiá»u nháº¥t Ä‘áº¿n káº¿t quáº£

---

## ğŸ“– References & Resources

**Datasets:**

- [VoxCeleb](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/)
- [Common Voice](https://commonvoice.mozilla.org/)
- [LibriSpeech](http://www.openslr.org/12/)

**Audio Feature Extraction:**

- [librosa Documentation](https://librosa.org/doc/latest/index.html)
- [Audio Signal Processing for ML](https://www.youtube.com/playlist?list=PLhA3b2k8R3t2Ng1WW_7MiXeh1pfQJQi_P)

**Vector Similarity Search:**

- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)
- [Pinecone Docs](https://docs.pinecone.io/)

**MFCC & Voice Features:**

- [Understanding MFCCs](https://medium.com/prathena/the-dummys-guide-to-mfcc-aceab2450fd)
- [Voice Feature Extraction](https://www.sciencedirect.com/topics/computer-science/voice-feature-extraction)

---

## ğŸ¯ Next Steps After Planning

1. **Review Plan:** NgÆ°á»i dÃ¹ng review vÃ  approve káº¿ hoáº¡ch
2. **Phase 3 (SOLUTIONING):** Thiáº¿t káº¿ chi tiáº¿t feature extraction pipeline
3. **Phase 4 (IMPLEMENTATION):** Báº¯t Ä‘áº§u code theo task breakdown
4. **Phase X (VERIFICATION):** Cháº¡y tests vÃ  demo

---

## Plan Status

- [x] Requirements analysis complete
- [x] Tech stack decided
- [x] File structure defined
- [x] Task breakdown created
- [ ] User approval pending

**Created:** 2026-01-29  
**Last Updated:** 2026-01-29  
**Plan File:** `voice-similarity-search.md`
